{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 09\n",
    "\n",
    "[![Open and Execute in Google Colaboratory](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/astrojuanlu/ie-mbd-python-data-analysis-i/blob/main/sessions/Session%2009.ipynb)\n",
    "\n",
    "- Tabular data with pandas DataFrames\n",
    "- Slicing and indexing pandas DataFrames\n",
    "- Filtering pandas DataFrames\n",
    "- 1-dimensional data: pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular data with pandas `DataFrame`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas is the most widely used Python library to read and manipulate tabular data. Its most important object is the `DataFrame`, which represents a rectangular table of rows and columns.\n",
    "\n",
    "To start using pandas, you need to import it first. The most common way to import pandas is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the pandas functions will be accessible under the `pd` alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` objects are rectangular tables formed by a number of columns. Each column can have a different `dtype`, but all of them must have the same number of rows.\n",
    "\n",
    "`DataFrame` objects can be created with the `DataFrame()` initializer, but in most cases they will appear as a result of other function or method calls, for example `pandas.read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/\"\n",
    "    \"raw/main/data/titanic.csv\"\n",
    ")\n",
    "# df = pd.read_csv(\"national_covid19.csv\", index_col=\"date\")  # You can specify the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good practice to display the first few rows of the `DataFrame` right after opening it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you can retrieve the `dtypes` of the `DataFrame` (it's no longer a single `dtype`!) as well as a few other important properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some clarifications:\n",
    "\n",
    "- The `object` dtype means something pandas couldn't parse. Could be a string, a string representing a date, or something completely different. In most cases it means `str`, but be careful when they appear.\n",
    "- `float64` is similar to `int64`: a floating point value with 64 bits of precision.\n",
    "- `NaN` means \"Not a Number\" and in general it means \"missing value\". In following sessions you will see how to effectively handle missing values, and what do they mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` objects have a large number of methods as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `object` columns are excluded. To include them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 1. CSV reading\n",
    "\n",
    "Read the `grandes-tenedores-madrid.csv` file and display\n",
    "- number of rows,\n",
    "- number of columns,\n",
    "- dtypes of the columns,\n",
    "- and the first five rows\n",
    "\n",
    "Tip: The path is `https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/raw/main/data/grandes-tenedores-madrid.csv`\n",
    "\n",
    "Data source: https://datos.civio.es/dataset/megatenedores-de-la-comunidad-de-madrid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract a single column, use the indexing syntax, like you would do with a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For anything else (retrieving a slice of columns, slicing both rows and columns), use the `.loc` accessor instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"Age\":]  # All rows, from the \"Age\" column to the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:5, [\"SibSp\", \"Parch\"]]  # Rows up to the one with the index 5 inclusive, columns \"SibSp\" and \"Parch\" only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    [100, 110],  # Rows labeled 100 and 110\n",
    "    [\"Fare\", \"Cabin\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these methods work for _any_ `DataFrame`. For example, the result of `.describe()` is _also_ a `DataFrame`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df.describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.loc[\"min\":\"max\", [\"Age\", \"Pclass\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering a `DataFrame` according to some condition is also done with the `.loc` accessor. For this, you can leverage the fact that operations between pandas `DataFrame` or `Series` objects and Python scalars are broadcasted automatically. In other words: operations are performed in sequence for all the elements of the pandas object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 100  # Returns False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fare\"] > 100  # Returns a Series of boolean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the previous `Series` contain any `True` value? You can check with the `.any()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_filter = df[\"Fare\"] > 100\n",
    "fare_filter.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_filter.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this filter or mask inside `.loc` to select a subset of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[fare_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining filters requires some care, because the usual boolean Python operators don't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 > 100) and (3 < 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"Fare\"] > 100) and (df[\"Fare\"] < 1_000)  # Fails!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To operate boolean pandas `Series`, you need to use the bitwise operators:\n",
    "\n",
    "- Bitwise OR `|`\n",
    "- Bitwise AND `&`\n",
    "- Bitwise NOT `~`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with cases_total between 100 and 1000\n",
    "fare_filter = (100 < df[\"Fare\"]) & (df[\"Fare\"] < 1_000)\n",
    "df.loc[fare_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cases where \"icu\" is not null, equivalent to\n",
    "# df.loc[df[\"icu\"].notnull()]\n",
    "df.loc[~df[\"Age\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Selecting rows and columns\n",
    "\n",
    "From the `grandes-tenedores-madrid.csv` dataset, select the rows where the column \"Inmuebles\" is larger than 300 and \"Subsector\" is not \"Fondos de inversión\".\n",
    "\n",
    "Then, keep only the columns \"NIF\", \"Matriz\", \"Sede empresa matriz\", and \"Sector\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-dimensional data: pandas `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the columns of a `DataFrame` is a `Series` object. `Series` are mutable (hence you can add, remove, and replace elements) and homogeneous (all its elements must have the same type). As you will see, `Series` can be indexed by numerical position (like lists) or by label (like dictionaries).\n",
    "\n",
    "For example, let's create a `Series` from a Python `list`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list(range(10, 15))\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(my_list)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` have an important property, the `dtype`, that holds the type of its individual elements. As you can see in the string representation of the `Series`, the `dtype` of `ser` is `int64`, which means that `ser` is a `Series` of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">The <code>64</code> part in <code>int64</code> alludes to how much memory does pandas use to store those integers, which is fixed to 64 bits. This means that, contrary to Python integers, there is a maximum integer pandas can store in an <code>int64</code>. But you don't need to worry about that now.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `pd.Series` receives heterogeneous input, it will cast everything to `object` and the `Series` will be less useful (no numerical operations will be allowed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([True, True, False])  # dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([True, True, False, 2])  # dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` objects have a large number of methods, including some typical statistical and aggregation ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.max(), ser.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.mean(), ser.median(), ser.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some more sophisticated methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.describe()\n",
    "# ser.describe([.33, .66, .99])  # notice that you can specify the percentiles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series made of non-numerical dtypes will have a different result for `.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, 2, 2, 2, 3.0, \"five\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` has some `values` and an `index`. The `index` will become very important when working with `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` objects can also be created from dictionaries, in which case the index will change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({\"a\": 1, \"b\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can refer to values by index using the `.loc` accessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Notice that we don't call <code>loc</code> a <em>method</em> because it is not called! It is a special object that \"abuses\" the indexing/slicing syntax. If you call it with parenthesis, you will get an error.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantics of `.loc` with respect to slicing are slightly different from the base ones from Python. Most importantly, the end of the slice is included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.loc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access items by numerical position instead, use `.iloc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2 = pd.Series({\"a\": 1, \"b\": 2})\n",
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.loc[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.loc[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Advanced: Managing semi-structured data\n",
    "\n",
    "Load the `rick-and-morty.json` data to a Python object, then store the episodes list in a variable `episodes`, then pass it to the method `pandas.DataFrame.from_records` to turn the list of episodes into a `DataFrame`.\n",
    "\n",
    "Then, answer the same questions from session 6, using exclusively pandas methods (no comprehensions or loops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DATA_URL = (\n",
    "    \"https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/\"\n",
    "    \"raw/main/data/rick-and-morty.json\"\n",
    ")\n",
    "\n",
    "data = requests.get(DATA_URL).json()\n",
    "print(type(data), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(data[\"_embedded\"][\"episodes\"])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
