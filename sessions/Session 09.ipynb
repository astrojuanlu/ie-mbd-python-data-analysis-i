{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 09\n",
    "\n",
    "[![Open and Execute in Google Colaboratory](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/astrojuanlu/ie-mbd-python-data-analysis-i/blob/main/sessions/Session%2009.ipynb)\n",
    "\n",
    "- Tabular data with pandas DataFrames\n",
    "- Slicing and indexing pandas DataFrames\n",
    "- Filtering pandas DataFrames\n",
    "- 1-dimensional data: pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular data with pandas `DataFrame`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas is the most widely used Python library to read and manipulate tabular data. Its most important object is the `DataFrame`, which represents a rectangular table of rows and columns.\n",
    "\n",
    "To start using pandas, you need to import it first. The most common way to import pandas is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the pandas functions will be accessible under the `pd` alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` objects are rectangular tables formed by a number of columns. Each column can have a different `dtype`, but all of them must have the same number of rows.\n",
    "\n",
    "`DataFrame` objects can be created with the `DataFrame()` initializer, but in most cases they will appear as a result of other function or method calls, for example `pandas.read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/\"\n",
    "    \"raw/main/data/titanic.csv\"\n",
    ")\n",
    "# df = pd.read_csv(\"national_covid19.csv\", index_col=\"date\")  # You can specify the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good practice to display the first few rows of the `DataFrame` right after opening it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you can retrieve the `dtypes` of the `DataFrame` (it's no longer a single `dtype`!) as well as a few other important properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some clarifications:\n",
    "\n",
    "- The `object` dtype means something pandas couldn't parse. Could be a string, a string representing a date, or something completely different. In most cases it means `str`, but be careful when they appear.\n",
    "- `float64` is similar to `int64`: a floating point value with 64 bits of precision.\n",
    "- `NaN` means \"Not a Number\" and in general it means \"missing value\". In following sessions you will see how to effectively handle missing values, and what do they mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` objects have a large number of methods as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `object` columns are excluded. To include them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 1. CSV reading\n",
    "\n",
    "Read the `grandes-tenedores-madrid.csv` file and display\n",
    "- number of rows,\n",
    "- number of columns,\n",
    "- dtypes of the columns,\n",
    "- and the first five rows\n",
    "\n",
    "Tip: The path is `https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/raw/main/data/grandes-tenedores-madrid.csv`\n",
    "\n",
    "Data source: https://datos.civio.es/dataset/megatenedores-de-la-comunidad-de-madrid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract a single column, use the indexing syntax, like you would do with a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For anything else (retrieving a slice of columns, slicing both rows and columns), use the `.loc` accessor instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"Age\":]  # All rows, from the \"Age\" column to the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:5, [\"SibSp\", \"Parch\"]]  # Rows up to the one with the index 5 inclusive, columns \"SibSp\" and \"Parch\" only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    [100, 110],  # Rows labeled 100 and 110\n",
    "    [\"Fare\", \"Cabin\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these methods work for _any_ `DataFrame`. For example, the result of `.describe()` is _also_ a `DataFrame`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df.describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.loc[\"min\":\"max\", [\"Age\", \"Pclass\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering a `DataFrame` according to some condition is also done with the `.loc` accessor. For this, you can leverage the fact that operations between pandas `DataFrame` or `Series` objects and Python scalars are broadcasted automatically. In other words: operations are performed in sequence for all the elements of the pandas object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 100  # Returns False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fare\"] > 100  # Returns a Series of boolean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the previous `Series` contain any `True` value? You can check with the `.any()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_filter = df[\"Fare\"] > 100\n",
    "fare_filter.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_filter.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this filter or mask inside `.loc` to select a subset of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[fare_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining filters requires some care, because the usual boolean Python operators don't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 > 100) and (3 < 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"Fare\"] > 100) and (df[\"Fare\"] < 1_000)  # Fails!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To operate boolean pandas `Series`, you need to use the bitwise operators:\n",
    "\n",
    "- Bitwise OR `|`\n",
    "- Bitwise AND `&`\n",
    "- Bitwise NOT `~`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with cases_total between 100 and 1000\n",
    "fare_filter = (100 < df[\"Fare\"]) & (df[\"Fare\"] < 1_000)\n",
    "df.loc[fare_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cases where \"icu\" is not null, equivalent to\n",
    "# df.loc[df[\"icu\"].notnull()]\n",
    "df.loc[~df[\"Age\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Selecting rows and columns\n",
    "\n",
    "From the `grandes-tenedores-madrid.csv` dataset, select the rows where the column \"Inmuebles\" is larger than 300 and \"Subsector\" is not \"Fondos de inversiÃ³n\".\n",
    "\n",
    "Then, keep only the columns \"NIF\", \"Matriz\", \"Sede empresa matriz\", and \"Sector\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-dimensional data: pandas `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the columns of a `DataFrame` is a `Series` object. `Series` are mutable (hence you can add, remove, and replace elements) and homogeneous (all its elements must have the same type). As you will see, `Series` can be indexed by numerical position (like lists) or by label (like dictionaries).\n",
    "\n",
    "For example, let's create a `Series` from a Python `list`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list(range(10, 15))\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(my_list)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` have an important property, the `dtype`, that holds the type of its individual elements. As you can see in the string representation of the `Series`, the `dtype` of `ser` is `int64`, which means that `ser` is a `Series` of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">The <code>64</code> part in <code>int64</code> alludes to how much memory does pandas use to store those integers, which is fixed to 64 bits. This means that, contrary to Python integers, there is a maximum integer pandas can store in an <code>int64</code>. But you don't need to worry about that now.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `pd.Series` receives heterogeneous input, it will cast everything to `object` and the `Series` will be less useful (no numerical operations will be allowed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([True, True, False])  # dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([True, True, False, 2])  # dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` objects have a large number of methods, including some typical statistical and aggregation ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.max(), ser.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.mean(), ser.median(), ser.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some more sophisticated methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.describe()\n",
    "# ser.describe([.33, .66, .99])  # notice that you can specify the percentiles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series made of non-numerical dtypes will have a different result for `.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, 2, 2, 2, 3.0, \"five\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` has some `values` and an `index`. The `index` will become very important when working with `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` objects can also be created from dictionaries, in which case the index will change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({\"a\": 1, \"b\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can refer to values by index using the `.loc` accessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Notice that we don't call <code>loc</code> a <em>method</em> because it is not called! It is a special object that \"abuses\" the indexing/slicing syntax. If you call it with parenthesis, you will get an error.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantics of `.loc` with respect to slicing are slightly different from the base ones from Python. Most importantly, the end of the slice is included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.loc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access items by numerical position instead, use `.iloc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2 = pd.Series({\"a\": 1, \"b\": 2})\n",
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.loc[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.loc[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Advanced: Managing semi-structured data\n",
    "\n",
    "Load the `rick-and-morty.json` data to a Python object, then store the episodes list in a variable `episodes`, then pass it to the method `pandas.DataFrame.from_records` to turn the list of episodes into a `DataFrame`.\n",
    "\n",
    "Then, answer the same questions from session 6, using exclusively pandas methods (no comprehensions or loops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DATA_URL = (\n",
    "    \"https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/\"\n",
    "    \"raw/main/data/rick-and-morty.json\"\n",
    ")\n",
    "\n",
    "data = requests.get(DATA_URL).json()\n",
    "print(type(data), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(data[\"_embedded\"][\"episodes\"])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
