{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0722a65c-e713-4736-97dc-04904f4c6dc9",
   "metadata": {},
   "source": [
    "# Session 10\n",
    "\n",
    "[![Open and Execute in Google Colaboratory](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/astrojuanlu/ie-mbd-python-data-analysis-i/blob/main/sessions/Session%2010.ipynb)\n",
    "\n",
    "- Reading semi-structured data into pandas\n",
    "- String methods on pandas columns\n",
    "- The \"group by and aggregate\" operation\n",
    "- The `agg` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed720d-86d9-40a2-a363-f4c5be3953be",
   "metadata": {},
   "source": [
    "## Reading semi-structured data into pandas\n",
    "\n",
    "pandas DataFrames are always table-like objects, but that doesn't mean that they're limited to CSV data. In fact, you can read many other formats using different `pandas.read_*` methods.\n",
    "\n",
    "For example, it's possible to read semi-structured data into a pandas DataFrame. Let's do an example with JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b735fc5-0c8d-493f-a79d-49e0d84aacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUESKY_DATA_URL = \"../data/bluesky_more_5000_likes_filtered.json\"\n",
    "BLUESKY_DATA_URL = (\n",
    "    \"https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/\"\n",
    "    \"raw/main/data/bluesky_more_5000_likes_filtered.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ec974-3551-4b83-9985-8c16ff4f80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(BLUESKY_DATA_URL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9a0d4-204a-4a49-9a4b-9d46ebe41b1f",
   "metadata": {},
   "source": [
    "Notice several things:\n",
    "\n",
    "(1) both the `text` and `langs` columns have dtype `object`, even though the former is made of strings and the latter is made of lists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e0622-3395-4d12-9a0c-173886d0d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b941510-19e9-442c-a5fd-a76cb694e870",
   "metadata": {},
   "source": [
    "(2) If a given field is present in at least one record, the records that don't have it will hold a `NaN` value. You will learn more about handling missing data in the next session."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3a39270-1737-44d3-9a0f-a2e45a32cb07",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Alternatively, you could also read this data using the `requests` package into a native Python object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cab469-aaa7-487c-9ed8-4fb8dbd71fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "import requests\n",
    "\n",
    "# data = json.load(open(BLUESKY_DATA_URL))\n",
    "data = requests.get(BLUESKY_DATA_URL).json()\n",
    "type(data), len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2e59f-f241-4b5c-a5e7-56271b40c73f",
   "metadata": {},
   "source": [
    "And then use one of the `pandas.DataFrame.from_*` methods (notice that these are on a different namespace than the `pandas.read_*` methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f5077f-609d-4e4a-8d95-ef7037dab014",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(data).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b7b9d-3dc9-400e-a929-b851c73afb8b",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 1. JSON reading\n",
    "\n",
    "The `rick-and-morty.json` data is not so easy to read directly as JSON. Go ahead and try it. What's the error?\n",
    "\n",
    "Use the alternative method: load the `rick-and-morty.json` data to a Python object, then store the episodes list in a variable `episodes`, then pass it to the method `pandas.DataFrame.from_records` to turn the list of episodes into a `DataFrame`.\n",
    "\n",
    "List the first 5 rows to verify that it was correctly loaded. **Notice that some columns contain dictionaries**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430d06e-0dee-4368-bdc3-1fcd8362f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "RICK_MORTY_DATA_URL = (\n",
    "    \"https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/\"\n",
    "    \"raw/main/data/rick-and-morty.json\"\n",
    ")\n",
    "\n",
    "rm_data = requests.get(RICK_MORTY_DATA_URL).json()\n",
    "print(type(rm_data), len(rm_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e220d-ab5c-4c39-852e-c8152df37d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43616cd-d5a6-47a4-aaba-a0c63bcaa7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_df = pd.DataFrame.from_records(data[\"_embedded\"][\"episodes\"])\n",
    "rm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc41f62-b31d-4a78-9a34-46ab2673851a",
   "metadata": {},
   "source": [
    "## The \"group by and aggregate\" operation\n",
    "\n",
    "Group by operations in pandas are essential to perform advanced aggregations. The concept and the syntax are directly borrowed from SQL, and follow a similar \"split-apply-combine\" procedure. At a very high level, this is what happens:\n",
    "\n",
    "![Group by and aggregate](../img/group-by-agg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40931e2d-7d47-4a26-aa65-add7d60e6437",
   "metadata": {},
   "source": [
    "Group by operations are initiated by calling the `groupby` method of a DataFrame. But notice that this returns an intermediate object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c705c53-f500-4e3f-a0c1-2bd20e065821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f278ec-73f1-42b5-8088-ef1590f6accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fea5ef-d2f6-4e2b-a99a-e75173eff0b8",
   "metadata": {},
   "source": [
    "To effectively use this object, you have to finalize the operation by calling an aggregation. The result will be another pandas object, with the index containing each of the distinct values of the column you are grouping by.\n",
    "\n",
    "For example, to know how many posts are there per instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a5ae5-671d-4112-ad54-be07307c9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"instance\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddae2de-3e60-47b5-aa8c-ecf87353124f",
   "metadata": {},
   "source": [
    "And to extract the first (earliest) post of each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07089ad0-c8f3-427a-921b-03b46583e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"instance\").first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2408514-16a7-4e9c-bc4b-47e421c72d84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3c76e5a-b8ed-4f6b-863a-38023d0fd86e",
   "metadata": {},
   "source": [
    "Some aggregations work with specific data types. For example, yhou might be interested in average statistics of some numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775301af-e266-4213-ae8d-3bbb85265710",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.loc[:, [\"instance\", \"like_count\", \"reply_count\"]]\n",
    "    .groupby(\"instance\")\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86ddbe-d6a1-471a-94f1-bb0084e56861",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercises\n",
    "\n",
    "### 2. Analyzing semi-structured data\n",
    "\n",
    "Answer the remaining questions about the Rick & Morty data from session 6, using exclusively pandas methods (no comprehensions or loops)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb2217-85be-41ef-9798-75a2bd8d95c6",
   "metadata": {},
   "source": [
    "## The `agg` method\n",
    "\n",
    "Sometimes you want to apply more complex aggregations, or stack several of them, or apply different aggregations to different columns. The `.agg` method of the `DataFrameGroupBy` allows you to do all that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b3878-1d97-438e-becd-02cd918f0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.loc[:, [\"instance\", \"like_count\", \"reply_count\"]]\n",
    "    .groupby(\"instance\")\n",
    "    .agg([\"mean\", \"std\"])  # A list of aggregation functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58a199-bde5-4eac-9380-5a66c494e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.loc[:, [\"instance\", \"like_count\", \"reply_count\"]]\n",
    "    .groupby(\"instance\")\n",
    "    .agg({\"like_count\": \"mean\", \"reply_count\": [\"sum\", \"std\"]})  # A dictionary/mapping of column names to aggregation functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7240464-11dd-48f4-82a4-0b570c75e5b9",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 3. More analysis of semi-structured data\n",
    "\n",
    "Load the Reddit data from Session 06 and answer the questions there, using exclusively pandas methods (no comprehensions or loops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216793ed-67bf-43c3-8c68-58db4c515e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDDIT_DATA_URL = (\n",
    "    \"https://github.com/astrojuanlu/ie-mbd-python-data-analysis-i/\"\n",
    "    \"raw/main/data/reddit_popular.json\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
